# GPT-4 Calibration as a Research Assistant in Economics

## Abstract

This paper defines the Plugin Forest, a best-practice prompt engineering strategy for research.
We then leverage crowd feedback to comparatively calibrate GPT-4 summary literature reviews against human-authored documents related to a variety of research topics within the field of economics.
We find that reviews constructed with a Plugin Forest obtain an average quality rating equal to doctorate-level researchers in the field.
Further, the high-quality documents generated by GPT-4 exhibited smaller quality variation compared to human-authored documents.
Notably, GPT-4 using the Plugin Forest technique generated literature reviews with zero hallucinated citations.
We find that GPT-4 quality is sensitive to paper topic, with lower performance for lesser-studied topics.
Further, graders were reliably unable to determine when a document was authored by GPT-4, even when the grader had a graduate education in the field.
Graders did not identify GPT-4 authored material as written by a doctorate, however, indicating a notable difference in style even while quality remains matched.
We conclude that authoring research using GPT-4 and the Plugin Forest reliably enhances researcher productivity with no loss in quality for a variety of tasks.

Authors: John, Josh

Keywords:

- GPT-4
- ChatGPT
- Economic Literature Review
- AI in Academic Research
- AI Augmentation
- Multimodal Models
- Research Productivity
- Prompt Engineering
- Tree of Thoughts

JEL Codes:

- C88 - Other Computer Software
- A11 - Role of Economics; Role of Economists; Market for Economists
- C80 - General (Data Collection and Data Estimation Methodology; Computer Programs)
- B41 - Economic Methodology
- I23 - Higher Education and Research Institutions

## Background and Introduction

- lots of research on large language models, but less on multimodal models like GPT-4
- we know generative ai task performance varies widely based on the particular task. today there is research on productivity does exist for knowledge work and research in general, and there is also some research on generative ai for financial analysis, but there is no direct research on the quality of economic research produced by GPT-4. We provide this and dive further to the level of research topics, providing nuance about when and how to use GPT-4 rather than mere top-line productivity estimates.
- this is really important because GPT-4 has higher task performance and broader task usage compared to LLMs
- GPT-4 provides unique productivity opportunities for researchers due to its ability to generate, improve, and execute code for data analysis and both read and create figures and tables. These tasks are not possible for pure large language models.
- lots of discussion about ChatGPT which disregards GPT-4, the most powerful form of ChatGPT
- people say chatgpt hallucinates and in many cases it has been directly contraindicated for academic work
- we know prompt strategy drives productivity, but research on GPT-4 that does exist fails to incorporate best-practice prompt techniques and leverage GPT-4 capabilities like plugins. Plugins importantly provide access to academic papers, and we know from research like "textbooks are all you need" that access to academic material is a very important driver of producing high-quality academic-level results.

## Methodology

TODO

## Results

#### Case Study Results

#### Generalized Case Study

- People couldn't tell it was GPT-4
- Even field doctorates couldn't tell

#### Regression Results

- 3 model table
- Regression of assessed education level on GPT Authorship

## Conclusion

TODO

## Appendices

- Questionnaire
